{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cfb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2309dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086a95a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readme.md         image-2.png       image-6.png       requirements.txt\n",
      "\u001b[30m\u001b[43mapp\u001b[m\u001b[m/              image-3.png       image.png\n",
      "\u001b[30m\u001b[43mdata\u001b[m\u001b[m/             image-4.png       \u001b[34mmlruns\u001b[m\u001b[m/\n",
      "image-1.png       image-5.png       \u001b[30m\u001b[43mnotebooks\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "616edb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimentos disponibles:\n",
      "1. report_summary_slms_vs_gpt4_1_reference\n"
     ]
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "# Cargamos experimentos que comiencen con \"eval_\"\n",
    "experiments = [\n",
    "    exp for exp in client.search_experiments() if exp.name.startswith(\"report_summary\")\n",
    "]\n",
    "\n",
    "if not experiments:\n",
    "   print(\"No hay experimentos disponibles.\")\n",
    "if experiments:\n",
    "    exp_names = [exp.name for exp in experiments]\n",
    "    print(\"Experimentos disponibles:\")\n",
    "    for i, exp in enumerate(exp_names):\n",
    "        print(f\"{i + 1}. {exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6e450ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 3100 ejecuciones registradas.\n"
     ]
    }
   ],
   "source": [
    "experiment = client.get_experiment_by_name(exp_names[0])\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\n",
    "        \"start_time DESC\",\n",
    "    ],\n",
    "    max_results=3500,\n",
    ")\n",
    "\n",
    "if not runs:\n",
    "    print(\"No hay ejecuciones registradas.\")\n",
    "else:\n",
    "    print(f\"Se encontraron {len(runs)} ejecuciones registradas.\")\n",
    "    # Recolectamos datos de cada run\n",
    "    data = []\n",
    "    for run in runs:\n",
    "        params = run.data.params\n",
    "        metrics = run.data.metrics\n",
    "        artifacts = client.list_artifacts(run.info.run_id)\n",
    "        list_artifacts = [artifact for artifact in artifacts]\n",
    "        dict_metrics = {\n",
    "            #'run_ID': run.info.run_id,\n",
    "            \"video_id\": params.get(\"video_id\"),\n",
    "            \"channel_name\": params.get(\"channel_name\"),\n",
    "            \"prompt_version\": params.get(\"prompt_version\"),\n",
    "            \"model\": params.get(\"llm_model\"),\n",
    "            # Métricas de evaluación\n",
    "            \"criterial_score\": metrics.get(\"criterial_score\", None),\n",
    "            \"embedding_cosine_distance\": metrics.get(\"embedding_cosine_distance\", None),\n",
    "            \"score\": metrics.get(\"score\", None),\n",
    "        }\n",
    "        data.append(dict_metrics)\n",
    "\n",
    "    # Creamos un dataframe con todos los datos\n",
    "    df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3e3e37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf2_Q4_k_m',\n",
       " None,\n",
       " 'phi4_latest',\n",
       " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf3_Q4_k_m',\n",
       " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf3_Q8_0',\n",
       " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf2_Q8_0',\n",
       " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0',\n",
       " 'llama3_1_8b_instruct_fp16',\n",
       " 'llama3_2_3b_instruct_fp16',\n",
       " 'gpt_4o_mini',\n",
       " 'hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest',\n",
       " 'llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c3a79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_models = [\n",
    " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf2_Q4_k_m',\n",
    " 'phi4_latest',\n",
    " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf3_Q4_k_m',\n",
    " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf3_Q8_0',\n",
    " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf2_Q8_0',\n",
    " 'llama3_1_8b_instruct_fp16',\n",
    " 'llama3_2_3b_instruct_fp16',\n",
    " 'gpt_4o_mini',\n",
    " 'llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a73c1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = df[df['model'].isin(sel_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec2b1218",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/3s22b27525jc3bm0m923h36h3wg489/T/ipykernel_35880/2935142726.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sel['model'] = df_sel['model'].replace(model_name_map)\n"
     ]
    }
   ],
   "source": [
    "# Diccionario de reemplazo de nombres de modelos\n",
    "model_name_map = {\n",
    " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf2_Q4_k_m':'finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q4_k_m',\n",
    " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf3_Q4_k_m':'finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q4_k_m',\n",
    " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf3_Q8_0':'finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q8_0',\n",
    " 'unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf2_Q8_0':'finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q8_0',\n",
    " 'llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest': 'finetune_qlora_litgpt_llama_3_2_3b_bnb_nf4_v2_q8_0',\n",
    "}\n",
    "\n",
    "# Reemplazar en la columna 'model' de df_sel\n",
    "df_sel['model'] = df_sel['model'].replace(model_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dd65726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2652 entries, 0 to 3099\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   video_id                   2652 non-null   object \n",
      " 1   channel_name               2652 non-null   object \n",
      " 2   prompt_version             2652 non-null   object \n",
      " 3   model                      2652 non-null   object \n",
      " 4   criterial_score            2652 non-null   float64\n",
      " 5   embedding_cosine_distance  2652 non-null   float64\n",
      " 6   score                      2652 non-null   float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 165.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b52fb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "test_dataset_path = 'data/slm_summaries/test_slm_llama3_2_3b_instruct_fp16_v3_summary_expert.csv'\n",
    "df_test = pd.read_csv(test_dataset_path,sep=\";\")\n",
    "\n",
    "# Crear el codificador para llama-3.2 (usa 'cl100k_base' como aproximación)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Contar tokens en la columna 'slm_summary'\n",
    "df_test[\"slm_tokens\"] = df_test[\"text\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "sel_columns =['video_id', 'channel_name','slm_tokens']\n",
    "df_test_filter = df_test[sel_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bfecde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2652.000000\n",
       "mean      7411.674208\n",
       "std       7622.575768\n",
       "min         38.000000\n",
       "25%       2381.000000\n",
       "50%       3661.000000\n",
       "75%      11824.000000\n",
       "max      31540.000000\n",
       "Name: slm_tokens, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined = pd.merge(df_sel, df_test_filter, on=[\"channel_name\", \"video_id\"], how=\"inner\", suffixes=('', '_test'))\n",
    "df_joined['slm_tokens'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7435bd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>criterial_score</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.601810</td>\n",
       "      <td>0.100755</td>\n",
       "      <td>8.479638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>5.977376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.366516</td>\n",
       "      <td>0.159266</td>\n",
       "      <td>5.674208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q4_k_m</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.173843</td>\n",
       "      <td>5.190045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.167421</td>\n",
       "      <td>0.185578</td>\n",
       "      <td>5.180995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q4_k_m</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.179423</td>\n",
       "      <td>5.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.171946</td>\n",
       "      <td>0.197469</td>\n",
       "      <td>4.506787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>0.202654</td>\n",
       "      <td>4.325792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finetune_qlora_litgpt_llama_3_2_3b_bnb_nf4_v2_q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.224712</td>\n",
       "      <td>3.330317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.225847</td>\n",
       "      <td>3.208145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.383360</td>\n",
       "      <td>2.873303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.428200</td>\n",
       "      <td>2.099548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              model  \\\n",
       "                                                                      \n",
       "5                                                       gpt_4o_mini   \n",
       "4     finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q8_0   \n",
       "2     finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q8_0   \n",
       "3   finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q4_k_m   \n",
       "10                                                      phi4_latest   \n",
       "1   finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q4_k_m   \n",
       "11                                                      phi4_latest   \n",
       "6                                         llama3_1_8b_instruct_fp16   \n",
       "0                finetune_qlora_litgpt_llama_3_2_3b_bnb_nf4_v2_q8_0   \n",
       "8                                         llama3_2_3b_instruct_fp16   \n",
       "7                                         llama3_1_8b_instruct_fp16   \n",
       "9                                         llama3_2_3b_instruct_fp16   \n",
       "\n",
       "                prompt_version criterial_score embedding_cosine_distance  \\\n",
       "                                          mean                      mean   \n",
       "5            v3_summary_expert        0.601810                  0.100755   \n",
       "4            v3_summary_expert        0.294118                  0.159226   \n",
       "2            v3_summary_expert        0.366516                  0.159266   \n",
       "3            v3_summary_expert        0.262443                  0.173843   \n",
       "10  v1_summary_expert_one_shot        0.167421                  0.185578   \n",
       "1            v3_summary_expert        0.285068                  0.179423   \n",
       "11           v3_summary_expert        0.171946                  0.197469   \n",
       "6   v1_summary_expert_one_shot        0.081448                  0.202654   \n",
       "0            v3_summary_expert        0.140271                  0.224712   \n",
       "8   v1_summary_expert_one_shot        0.027149                  0.225847   \n",
       "7            v3_summary_expert        0.049774                  0.383360   \n",
       "9            v3_summary_expert        0.027149                  0.428200   \n",
       "\n",
       "       score  \n",
       "        mean  \n",
       "5   8.479638  \n",
       "4   5.977376  \n",
       "2   5.674208  \n",
       "3   5.190045  \n",
       "10  5.180995  \n",
       "1   5.153846  \n",
       "11  4.506787  \n",
       "6   4.325792  \n",
       "0   3.330317  \n",
       "8   3.208145  \n",
       "7   2.873303  \n",
       "9   2.099548  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df_sel.drop(columns=[\"video_id\", \"channel_name\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    #.agg(['mean','median','std','min','max'])\n",
    "    .agg(['mean'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Ordenar de mayor a menor por el score medio\n",
    "df_grouped_1 = df_grouped_1.sort_values(('score', 'mean'), ascending=False)\n",
    "df_grouped_1.to_csv(\"data/results/results_all.csv\")\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5609f04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrando por Chunk Size menor a 4096\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>criterial_score</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.086980</td>\n",
       "      <td>8.733871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.136306</td>\n",
       "      <td>6.887097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.135291</td>\n",
       "      <td>6.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q4_k_m</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.427419</td>\n",
       "      <td>0.150576</td>\n",
       "      <td>6.314516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.162088</td>\n",
       "      <td>6.193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q4_k_m</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.395161</td>\n",
       "      <td>0.144866</td>\n",
       "      <td>6.177419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.282258</td>\n",
       "      <td>0.167122</td>\n",
       "      <td>5.532258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.180236</td>\n",
       "      <td>5.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finetune_qlora_litgpt_llama_3_2_3b_bnb_nf4_v2_q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.194879</td>\n",
       "      <td>4.209677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.206691</td>\n",
       "      <td>3.790323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.309957</td>\n",
       "      <td>3.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.384256</td>\n",
       "      <td>2.701613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              model  \\\n",
       "                                                                      \n",
       "5                                                       gpt_4o_mini   \n",
       "4     finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q8_0   \n",
       "2     finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q8_0   \n",
       "1   finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q4_k_m   \n",
       "10                                                      phi4_latest   \n",
       "3   finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q4_k_m   \n",
       "11                                                      phi4_latest   \n",
       "6                                         llama3_1_8b_instruct_fp16   \n",
       "0                finetune_qlora_litgpt_llama_3_2_3b_bnb_nf4_v2_q8_0   \n",
       "8                                         llama3_2_3b_instruct_fp16   \n",
       "7                                         llama3_1_8b_instruct_fp16   \n",
       "9                                         llama3_2_3b_instruct_fp16   \n",
       "\n",
       "                prompt_version criterial_score embedding_cosine_distance  \\\n",
       "                                          mean                      mean   \n",
       "5            v3_summary_expert        0.685484                  0.086980   \n",
       "4            v3_summary_expert        0.387097                  0.136306   \n",
       "2            v3_summary_expert        0.516129                  0.135291   \n",
       "1            v3_summary_expert        0.427419                  0.150576   \n",
       "10  v1_summary_expert_one_shot        0.290323                  0.162088   \n",
       "3            v3_summary_expert        0.395161                  0.144866   \n",
       "11           v3_summary_expert        0.282258                  0.167122   \n",
       "6   v1_summary_expert_one_shot        0.145161                  0.180236   \n",
       "0            v3_summary_expert        0.193548                  0.194879   \n",
       "8   v1_summary_expert_one_shot        0.048387                  0.206691   \n",
       "7            v3_summary_expert        0.080645                  0.309957   \n",
       "9            v3_summary_expert        0.048387                  0.384256   \n",
       "\n",
       "       score  \n",
       "        mean  \n",
       "5   8.733871  \n",
       "4   6.887097  \n",
       "2   6.806452  \n",
       "1   6.314516  \n",
       "10  6.193548  \n",
       "3   6.177419  \n",
       "11  5.532258  \n",
       "6   5.129032  \n",
       "0   4.209677  \n",
       "8   3.790323  \n",
       "7   3.645161  \n",
       "9   2.701613  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context = 4096 # block_size=8192 or max_seq_length: 4096\n",
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "print(f\"Filtrando por Chunk Size menor a {context}\")\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]<=context].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    #.agg(['mean','median','std','min','max'])\n",
    "    .agg(['mean'])\n",
    "    .reset_index()\n",
    ")\n",
    "df_grouped_1 = df_grouped_1.sort_values(('score', 'mean'), ascending=False)\n",
    "df_grouped_1.to_csv(f\"data/results/results_{context}.csv\")\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd0ed122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrando por Chunk Size menor a 8192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>criterial_score</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.090291</td>\n",
       "      <td>8.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.348101</td>\n",
       "      <td>0.146064</td>\n",
       "      <td>6.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.468354</td>\n",
       "      <td>0.144579</td>\n",
       "      <td>6.398734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q4_k_m</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.164136</td>\n",
       "      <td>5.860759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q4_k_m</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.335443</td>\n",
       "      <td>0.157919</td>\n",
       "      <td>5.810127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.234177</td>\n",
       "      <td>0.173449</td>\n",
       "      <td>5.740506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.234177</td>\n",
       "      <td>0.178007</td>\n",
       "      <td>5.177215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.189635</td>\n",
       "      <td>4.822785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finetune_qlora_litgpt_llama_3_2_3b_bnb_nf4_v2_q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.203034</td>\n",
       "      <td>3.879747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.214628</td>\n",
       "      <td>3.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>0.314121</td>\n",
       "      <td>3.373418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.408168</td>\n",
       "      <td>2.449367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              model  \\\n",
       "                                                                      \n",
       "5                                                       gpt_4o_mini   \n",
       "4     finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q8_0   \n",
       "2     finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q8_0   \n",
       "1   finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q4_k_m   \n",
       "3   finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q4_k_m   \n",
       "10                                                      phi4_latest   \n",
       "11                                                      phi4_latest   \n",
       "6                                         llama3_1_8b_instruct_fp16   \n",
       "0                finetune_qlora_litgpt_llama_3_2_3b_bnb_nf4_v2_q8_0   \n",
       "8                                         llama3_2_3b_instruct_fp16   \n",
       "7                                         llama3_1_8b_instruct_fp16   \n",
       "9                                         llama3_2_3b_instruct_fp16   \n",
       "\n",
       "                prompt_version criterial_score embedding_cosine_distance  \\\n",
       "                                          mean                      mean   \n",
       "5            v3_summary_expert        0.645570                  0.090291   \n",
       "4            v3_summary_expert        0.348101                  0.146064   \n",
       "2            v3_summary_expert        0.468354                  0.144579   \n",
       "1            v3_summary_expert        0.367089                  0.164136   \n",
       "3            v3_summary_expert        0.335443                  0.157919   \n",
       "10  v1_summary_expert_one_shot        0.234177                  0.173449   \n",
       "11           v3_summary_expert        0.234177                  0.178007   \n",
       "6   v1_summary_expert_one_shot        0.113924                  0.189635   \n",
       "0            v3_summary_expert        0.164557                  0.203034   \n",
       "8   v1_summary_expert_one_shot        0.037975                  0.214628   \n",
       "7            v3_summary_expert        0.069620                  0.314121   \n",
       "9            v3_summary_expert        0.037975                  0.408168   \n",
       "\n",
       "       score  \n",
       "        mean  \n",
       "5   8.683544  \n",
       "4   6.569620  \n",
       "2   6.398734  \n",
       "1   5.860759  \n",
       "3   5.810127  \n",
       "10  5.740506  \n",
       "11  5.177215  \n",
       "6   4.822785  \n",
       "0   3.879747  \n",
       "8   3.569620  \n",
       "7   3.373418  \n",
       "9   2.449367  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context = 8192 # block_size=8192 or max_seq_length: 4096, # valor maximo promedio de los ultimos años sin canal USACRIPTOMONEDAS = 6000\n",
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "print(f\"Filtrando por Chunk Size menor a {context}\")\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]<=context].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "     #.agg(['mean','median','std','min','max'])\n",
    "    .agg(['mean'])\n",
    "    .reset_index()\n",
    ")\n",
    "df_grouped_1 = df_grouped_1.sort_values(('score', 'mean'), ascending=False)\n",
    "df_grouped_1.to_csv(f\"data/results/results_{context}.csv\")\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "861943ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrando por Chunk Size menor a 14000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>criterial_score</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.094007</td>\n",
       "      <td>8.653409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.151314</td>\n",
       "      <td>6.397727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.150443</td>\n",
       "      <td>6.232955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q4_k_m</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.335227</td>\n",
       "      <td>0.168733</td>\n",
       "      <td>5.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q4_k_m</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.163165</td>\n",
       "      <td>5.630682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.210227</td>\n",
       "      <td>0.177232</td>\n",
       "      <td>5.568182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.215909</td>\n",
       "      <td>0.185998</td>\n",
       "      <td>4.988636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.194388</td>\n",
       "      <td>4.653409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finetune_qlora_litgpt_llama_3_2_3b_bnb_nf4_v2_q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.208327</td>\n",
       "      <td>3.710227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.219727</td>\n",
       "      <td>3.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.336060</td>\n",
       "      <td>3.198864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.415605</td>\n",
       "      <td>2.323864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              model  \\\n",
       "                                                                      \n",
       "5                                                       gpt_4o_mini   \n",
       "4     finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q8_0   \n",
       "2     finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q8_0   \n",
       "1   finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v2_Q4_k_m   \n",
       "3   finetune_qlora_unsloth_llama_3_1_8B_Instruct_bnb_4bit_v3_Q4_k_m   \n",
       "10                                                      phi4_latest   \n",
       "11                                                      phi4_latest   \n",
       "6                                         llama3_1_8b_instruct_fp16   \n",
       "0                finetune_qlora_litgpt_llama_3_2_3b_bnb_nf4_v2_q8_0   \n",
       "8                                         llama3_2_3b_instruct_fp16   \n",
       "7                                         llama3_1_8b_instruct_fp16   \n",
       "9                                         llama3_2_3b_instruct_fp16   \n",
       "\n",
       "                prompt_version criterial_score embedding_cosine_distance  \\\n",
       "                                          mean                      mean   \n",
       "5            v3_summary_expert        0.625000                  0.094007   \n",
       "4            v3_summary_expert        0.340909                  0.151314   \n",
       "2            v3_summary_expert        0.431818                  0.150443   \n",
       "1            v3_summary_expert        0.335227                  0.168733   \n",
       "3            v3_summary_expert        0.318182                  0.163165   \n",
       "10  v1_summary_expert_one_shot        0.210227                  0.177232   \n",
       "11           v3_summary_expert        0.215909                  0.185998   \n",
       "6   v1_summary_expert_one_shot        0.102273                  0.194388   \n",
       "0            v3_summary_expert        0.159091                  0.208327   \n",
       "8   v1_summary_expert_one_shot        0.034091                  0.219727   \n",
       "7            v3_summary_expert        0.062500                  0.336060   \n",
       "9            v3_summary_expert        0.034091                  0.415605   \n",
       "\n",
       "       score  \n",
       "        mean  \n",
       "5   8.653409  \n",
       "4   6.397727  \n",
       "2   6.232955  \n",
       "1   5.659091  \n",
       "3   5.630682  \n",
       "10  5.568182  \n",
       "11  4.988636  \n",
       "6   4.653409  \n",
       "0   3.710227  \n",
       "8   3.454545  \n",
       "7   3.198864  \n",
       "9   2.323864  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context = 14000 # block_size=8192 or max_seq_length: 4096, # valor maximo promedio de los ultimos años sin canal USACRIPTOMONEDAS = 6000\n",
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "print(f\"Filtrando por Chunk Size menor a {context}\")\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]<=context].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "     #.agg(['mean','median','std','min','max'])\n",
    "    .agg(['mean'])\n",
    "    .reset_index()\n",
    ")\n",
    "df_grouped_1 = df_grouped_1.sort_values(('score', 'mean'), ascending=False)\n",
    "df_grouped_1.to_csv(f\"data/results/results_{context}.csv\")\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
