{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cfb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2309dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086a95a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readme.md         \u001b[30m\u001b[43mdata\u001b[m\u001b[m/             \u001b[30m\u001b[43mnotebooks\u001b[m\u001b[m/\n",
      "\u001b[30m\u001b[43mapp\u001b[m\u001b[m/              \u001b[34mmlruns\u001b[m\u001b[m/           requirements.txt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "616edb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimentos disponibles:\n",
      "1. report_summary_slms_vs_gpt4_1_reference\n"
     ]
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "# Cargamos experimentos que comiencen con \"eval_\"\n",
    "experiments = [\n",
    "    exp for exp in client.search_experiments() if exp.name.startswith(\"report_summary\")\n",
    "]\n",
    "\n",
    "if not experiments:\n",
    "   print(\"No hay experimentos disponibles.\")\n",
    "if experiments:\n",
    "    exp_names = [exp.name for exp in experiments]\n",
    "    print(\"Experimentos disponibles:\")\n",
    "    for i, exp in enumerate(exp_names):\n",
    "        print(f\"{i + 1}. {exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6e450ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 442 ejecuciones registradas.\n"
     ]
    }
   ],
   "source": [
    "experiment = client.get_experiment_by_name(exp_names[0])\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\n",
    "        \"start_time DESC\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "if not runs:\n",
    "    print(\"No hay ejecuciones registradas.\")\n",
    "else:\n",
    "    print(f\"Se encontraron {len(runs)} ejecuciones registradas.\")\n",
    "    # Recolectamos datos de cada run\n",
    "    data = []\n",
    "    for run in runs:\n",
    "        params = run.data.params\n",
    "        metrics = run.data.metrics\n",
    "        artifacts = client.list_artifacts(run.info.run_id)\n",
    "        list_artifacts = [artifact for artifact in artifacts]\n",
    "        dict_metrics = {\n",
    "            #'run_ID': run.info.run_id,\n",
    "            \"video_id\": params.get(\"video_id\"),\n",
    "            \"channel_name\": params.get(\"channel_name\"),\n",
    "            \"prompt_version\": params.get(\"prompt_version\"),\n",
    "            \"model\": params.get(\"llm_model\"),\n",
    "            # Métricas de evaluación\n",
    "            \"criterial_score\": metrics.get(\"criterial_score\", None),\n",
    "            \"embedding_cosine_distance\": metrics.get(\"embedding_cosine_distance\", None),\n",
    "            \"score\": metrics.get(\"score\", None),\n",
    "        }\n",
    "        data.append(dict_metrics)\n",
    "\n",
    "    # Creamos un dataframe con todos los datos\n",
    "    df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dd65726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   video_id                   442 non-null    object \n",
      " 1   channel_name               442 non-null    object \n",
      " 2   prompt_version             442 non-null    object \n",
      " 3   model                      442 non-null    object \n",
      " 4   criterial_score            442 non-null    float64\n",
      " 5   embedding_cosine_distance  442 non-null    float64\n",
      " 6   score                      442 non-null    float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 24.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cab9c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221 entries, 0 to 220\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   video_id      221 non-null    object\n",
      " 1   channel_name  221 non-null    object\n",
      " 2   prompt        221 non-null    object\n",
      " 3   text          221 non-null    object\n",
      " 4   summary       221 non-null    object\n",
      " 5   slm_prompt    221 non-null    object\n",
      " 6   slm_summary   221 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 12.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_dataset_path = 'data/slm_summaries/test_slm_llama3_2_3b_instruct_fp16_v3_summary_expert.csv'\n",
    "df_test = pd.read_csv(test_dataset_path,sep=\";\")\n",
    "\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b52fb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "# Crear el codificador para llama-3.2 (usa 'cl100k_base' como aproximación)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Contar tokens en la columna 'slm_summary'\n",
    "df_test[\"slm_tokens\"] = df_test[\"slm_prompt\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "sel_columns =['video_id', 'channel_name','slm_tokens']\n",
    "df_test_filter = df_test[sel_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bfecde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   video_id                   442 non-null    object \n",
      " 1   channel_name               442 non-null    object \n",
      " 2   prompt_version             442 non-null    object \n",
      " 3   model                      442 non-null    object \n",
      " 4   criterial_score            442 non-null    float64\n",
      " 5   embedding_cosine_distance  442 non-null    float64\n",
      " 6   score                      442 non-null    float64\n",
      " 7   slm_tokens                 442 non-null    int64  \n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 27.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>model</th>\n",
       "      <th>criterial_score</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>score</th>\n",
       "      <th>slm_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QEzWdecJPKM</td>\n",
       "      <td>USACRYPTONOTICIAS</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104214</td>\n",
       "      <td>7.0</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oi9z9YkeUZ8</td>\n",
       "      <td>USACRYPTONOTICIAS</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208968</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F4-oXv3oB9w</td>\n",
       "      <td>USACRYPTONOTICIAS</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140089</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84zFrrHaBCw</td>\n",
       "      <td>USACRYPTONOTICIAS</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167937</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kE4PHBzjK9w</td>\n",
       "      <td>USACRYPTONOTICIAS</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.112821</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id       channel_name     prompt_version  \\\n",
       "0  QEzWdecJPKM  USACRYPTONOTICIAS  v3_summary_expert   \n",
       "1  oi9z9YkeUZ8  USACRYPTONOTICIAS  v3_summary_expert   \n",
       "2  F4-oXv3oB9w  USACRYPTONOTICIAS  v3_summary_expert   \n",
       "3  84zFrrHaBCw  USACRYPTONOTICIAS  v3_summary_expert   \n",
       "4  kE4PHBzjK9w  USACRYPTONOTICIAS  v3_summary_expert   \n",
       "\n",
       "                                               model  criterial_score  \\\n",
       "0  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...              1.0   \n",
       "1  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...              0.0   \n",
       "2  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...              0.0   \n",
       "3  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...              0.0   \n",
       "4  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...              1.0   \n",
       "\n",
       "   embedding_cosine_distance  score  slm_tokens  \n",
       "0                   0.104214    7.0         816  \n",
       "1                   0.208968    2.0        5117  \n",
       "2                   0.140089    2.0       21970  \n",
       "3                   0.167937    5.0        2216  \n",
       "4                   0.112821    7.0        1604  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined = pd.merge(df, df_test_filter, on=[\"channel_name\", \"video_id\"], how=\"inner\", suffixes=('', '_test'))\n",
    "df_joined.info()\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7435bd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>criterial_score</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.428200</td>\n",
       "      <td>2.099548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.224712</td>\n",
       "      <td>3.330317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     prompt_version  \\\n",
       "                                                                          \n",
       "0                          llama3_2_3b_instruct_fp16  v3_summary_expert   \n",
       "1  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...  v3_summary_expert   \n",
       "\n",
       "  criterial_score embedding_cosine_distance     score  \n",
       "             mean                      mean      mean  \n",
       "0        0.027149                  0.428200  2.099548  \n",
       "1        0.140271                  0.224712  3.330317  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df.drop(columns=[\"video_id\", \"channel_name\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    .agg(['mean']) #.agg(['min', 'max' , 'sum', 'median','mean'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_grouped_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd0ed122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th colspan=\"2\" halign=\"left\">criterial_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">embedding_cosine_distance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>119</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>119</td>\n",
       "      <td>0.380516</td>\n",
       "      <td>119</td>\n",
       "      <td>2.756303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>119</td>\n",
       "      <td>0.201681</td>\n",
       "      <td>119</td>\n",
       "      <td>0.192671</td>\n",
       "      <td>119</td>\n",
       "      <td>4.268908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     prompt_version  \\\n",
       "                                                                          \n",
       "0                          llama3_2_3b_instruct_fp16  v3_summary_expert   \n",
       "1  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...  v3_summary_expert   \n",
       "\n",
       "  criterial_score           embedding_cosine_distance           score  \\\n",
       "            count      mean                     count      mean count   \n",
       "0             119  0.050420                       119  0.380516   119   \n",
       "1             119  0.201681                       119  0.192671   119   \n",
       "\n",
       "             \n",
       "       mean  \n",
       "0  2.756303  \n",
       "1  4.268908  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contex = 4096 # block_size=8192 or max_seq_length: 4096\n",
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]<contex].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    .agg(['count','mean'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_grouped_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7504820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th colspan=\"2\" halign=\"left\">criterial_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">embedding_cosine_distance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102</td>\n",
       "      <td>0.483832</td>\n",
       "      <td>102</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>102</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>102</td>\n",
       "      <td>0.262093</td>\n",
       "      <td>102</td>\n",
       "      <td>2.235294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     prompt_version  \\\n",
       "                                                                          \n",
       "0                          llama3_2_3b_instruct_fp16  v3_summary_expert   \n",
       "1  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_...  v3_summary_expert   \n",
       "\n",
       "  criterial_score           embedding_cosine_distance           score  \\\n",
       "            count      mean                     count      mean count   \n",
       "0             102  0.000000                       102  0.483832   102   \n",
       "1             102  0.068627                       102  0.262093   102   \n",
       "\n",
       "             \n",
       "       mean  \n",
       "0  1.333333  \n",
       "1  2.235294  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]>=contex].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    .agg(['count','mean'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_grouped_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
