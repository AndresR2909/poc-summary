{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cfb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2309dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086a95a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readme.md         \u001b[30m\u001b[43mdata\u001b[m\u001b[m/             \u001b[34mmlruns\u001b[m\u001b[m/           requirements.txt\n",
      "\u001b[30m\u001b[43mapp\u001b[m\u001b[m/              image.png         \u001b[30m\u001b[43mnotebooks\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616edb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimentos disponibles:\n",
      "1. report_summary_slms_vs_gpt4_1_reference\n"
     ]
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "# Cargamos experimentos que comiencen con \"eval_\"\n",
    "experiments = [\n",
    "    exp for exp in client.search_experiments() if exp.name.startswith(\"report_summary\")\n",
    "]\n",
    "\n",
    "if not experiments:\n",
    "   print(\"No hay experimentos disponibles.\")\n",
    "if experiments:\n",
    "    exp_names = [exp.name for exp in experiments]\n",
    "    print(\"Experimentos disponibles:\")\n",
    "    for i, exp in enumerate(exp_names):\n",
    "        print(f\"{i + 1}. {exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6e450ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 1108 ejecuciones registradas.\n"
     ]
    }
   ],
   "source": [
    "experiment = client.get_experiment_by_name(exp_names[0])\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\n",
    "        \"start_time DESC\",\n",
    "    ],\n",
    "    max_results=2000,\n",
    ")\n",
    "\n",
    "if not runs:\n",
    "    print(\"No hay ejecuciones registradas.\")\n",
    "else:\n",
    "    print(f\"Se encontraron {len(runs)} ejecuciones registradas.\")\n",
    "    # Recolectamos datos de cada run\n",
    "    data = []\n",
    "    for run in runs:\n",
    "        params = run.data.params\n",
    "        metrics = run.data.metrics\n",
    "        artifacts = client.list_artifacts(run.info.run_id)\n",
    "        list_artifacts = [artifact for artifact in artifacts]\n",
    "        dict_metrics = {\n",
    "            #'run_ID': run.info.run_id,\n",
    "            \"video_id\": params.get(\"video_id\"),\n",
    "            \"channel_name\": params.get(\"channel_name\"),\n",
    "            \"prompt_version\": params.get(\"prompt_version\"),\n",
    "            \"model\": params.get(\"llm_model\"),\n",
    "            # Métricas de evaluación\n",
    "            \"criterial_score\": metrics.get(\"criterial_score\", None),\n",
    "            \"embedding_cosine_distance\": metrics.get(\"embedding_cosine_distance\", None),\n",
    "            \"score\": metrics.get(\"score\", None),\n",
    "        }\n",
    "        data.append(dict_metrics)\n",
    "\n",
    "    # Creamos un dataframe con todos los datos\n",
    "    df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dd65726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1108 entries, 0 to 1107\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   video_id                   1106 non-null   object \n",
      " 1   channel_name               1106 non-null   object \n",
      " 2   prompt_version             1106 non-null   object \n",
      " 3   model                      1106 non-null   object \n",
      " 4   criterial_score            1106 non-null   float64\n",
      " 5   embedding_cosine_distance  1106 non-null   float64\n",
      " 6   score                      1106 non-null   float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 60.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cab9c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221 entries, 0 to 220\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   video_id      221 non-null    object\n",
      " 1   channel_name  221 non-null    object\n",
      " 2   prompt        221 non-null    object\n",
      " 3   text          221 non-null    object\n",
      " 4   summary       221 non-null    object\n",
      " 5   slm_prompt    221 non-null    object\n",
      " 6   slm_summary   221 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 12.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_dataset_path = 'data/slm_summaries/test_slm_llama3_2_3b_instruct_fp16_v3_summary_expert.csv'\n",
    "df_test = pd.read_csv(test_dataset_path,sep=\";\")\n",
    "\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b52fb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "# Crear el codificador para llama-3.2 (usa 'cl100k_base' como aproximación)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Contar tokens en la columna 'slm_summary'\n",
    "df_test[\"slm_tokens\"] = df_test[\"text\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "sel_columns =['video_id', 'channel_name','slm_tokens']\n",
    "df_test_filter = df_test[sel_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bfecde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1106 entries, 0 to 1105\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   video_id                   1106 non-null   object \n",
      " 1   channel_name               1106 non-null   object \n",
      " 2   prompt_version             1106 non-null   object \n",
      " 3   model                      1106 non-null   object \n",
      " 4   criterial_score            1106 non-null   float64\n",
      " 5   embedding_cosine_distance  1106 non-null   float64\n",
      " 6   score                      1106 non-null   float64\n",
      " 7   slm_tokens                 1106 non-null   int64  \n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 69.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>model</th>\n",
       "      <th>criterial_score</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>score</th>\n",
       "      <th>slm_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QEzWdecJPKM</td>\n",
       "      <td>USACRYPTONOTICIAS</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.092966</td>\n",
       "      <td>9.0</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oi9z9YkeUZ8</td>\n",
       "      <td>USACRYPTONOTICIAS</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.091710</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F4-oXv3oB9w</td>\n",
       "      <td>USACRYPTONOTICIAS</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.088294</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84zFrrHaBCw</td>\n",
       "      <td>USACRYPTONOTICIAS</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kE4PHBzjK9w</td>\n",
       "      <td>USACRYPTONOTICIAS</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095885</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id       channel_name     prompt_version        model  \\\n",
       "0  QEzWdecJPKM  USACRYPTONOTICIAS  v3_summary_expert  gpt_4o_mini   \n",
       "1  oi9z9YkeUZ8  USACRYPTONOTICIAS  v3_summary_expert  gpt_4o_mini   \n",
       "2  F4-oXv3oB9w  USACRYPTONOTICIAS  v3_summary_expert  gpt_4o_mini   \n",
       "3  84zFrrHaBCw  USACRYPTONOTICIAS  v3_summary_expert  gpt_4o_mini   \n",
       "4  kE4PHBzjK9w  USACRYPTONOTICIAS  v3_summary_expert  gpt_4o_mini   \n",
       "\n",
       "   criterial_score  embedding_cosine_distance  score  slm_tokens  \n",
       "0              1.0                   0.092966    9.0         649  \n",
       "1              1.0                   0.091710    9.0        4950  \n",
       "2              1.0                   0.088294    8.0       21803  \n",
       "3              1.0                   0.096579    9.0        2049  \n",
       "4              1.0                   0.095885    9.0        1437  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined = pd.merge(df, df_test_filter, on=[\"channel_name\", \"video_id\"], how=\"inner\", suffixes=('', '_test'))\n",
    "df_joined.info()\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7435bd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th colspan=\"2\" halign=\"left\">criterial_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">embedding_cosine_distance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>221</td>\n",
       "      <td>0.601810</td>\n",
       "      <td>221</td>\n",
       "      <td>0.100755</td>\n",
       "      <td>221</td>\n",
       "      <td>8.479638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>222</td>\n",
       "      <td>0.130631</td>\n",
       "      <td>222</td>\n",
       "      <td>0.232396</td>\n",
       "      <td>222</td>\n",
       "      <td>3.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v2_summary_expert_one_shot</td>\n",
       "      <td>221</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>221</td>\n",
       "      <td>0.309760</td>\n",
       "      <td>221</td>\n",
       "      <td>1.642534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>221</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>221</td>\n",
       "      <td>0.428200</td>\n",
       "      <td>221</td>\n",
       "      <td>2.099548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>221</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>221</td>\n",
       "      <td>0.224712</td>\n",
       "      <td>221</td>\n",
       "      <td>3.330317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    model  \\\n",
       "                                                            \n",
       "0                                             gpt_4o_mini   \n",
       "1    hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest   \n",
       "2                               llama3_2_3b_instruct_fp16   \n",
       "3                               llama3_2_3b_instruct_fp16   \n",
       "4  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest   \n",
       "\n",
       "               prompt_version criterial_score            \\\n",
       "                                        count      mean   \n",
       "0           v3_summary_expert             221  0.601810   \n",
       "1           v3_summary_expert             222  0.130631   \n",
       "2  v2_summary_expert_one_shot             221  0.018100   \n",
       "3           v3_summary_expert             221  0.027149   \n",
       "4           v3_summary_expert             221  0.140271   \n",
       "\n",
       "  embedding_cosine_distance           score            \n",
       "                      count      mean count      mean  \n",
       "0                       221  0.100755   221  8.479638  \n",
       "1                       222  0.232396   222  3.216216  \n",
       "2                       221  0.309760   221  1.642534  \n",
       "3                       221  0.428200   221  2.099548  \n",
       "4                       221  0.224712   221  3.330317  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df.drop(columns=[\"video_id\", \"channel_name\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    .agg(['count','mean']) #.agg(['min', 'max' , 'sum', 'median','mean'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd0ed122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>criterial_score</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.086980</td>\n",
       "      <td>8.733871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.198556</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v2_summary_expert_one_shot</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.282160</td>\n",
       "      <td>1.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.384256</td>\n",
       "      <td>2.701613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.194879</td>\n",
       "      <td>4.209677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    model  \\\n",
       "                                                            \n",
       "0                                             gpt_4o_mini   \n",
       "1    hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest   \n",
       "2                               llama3_2_3b_instruct_fp16   \n",
       "3                               llama3_2_3b_instruct_fp16   \n",
       "4  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest   \n",
       "\n",
       "               prompt_version criterial_score embedding_cosine_distance  \\\n",
       "                                         mean                      mean   \n",
       "0           v3_summary_expert        0.685484                  0.086980   \n",
       "1           v3_summary_expert        0.208000                  0.198556   \n",
       "2  v2_summary_expert_one_shot        0.032258                  0.282160   \n",
       "3           v3_summary_expert        0.048387                  0.384256   \n",
       "4           v3_summary_expert        0.193548                  0.194879   \n",
       "\n",
       "      score  \n",
       "       mean  \n",
       "0  8.733871  \n",
       "1  4.000000  \n",
       "2  1.967742  \n",
       "3  2.701613  \n",
       "4  4.209677  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contex = 4096 # block_size=8192 or max_seq_length: 4096\n",
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]<=contex].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    .agg(['mean'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7504820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>criterial_score</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.494845</td>\n",
       "      <td>0.118363</td>\n",
       "      <td>8.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.276004</td>\n",
       "      <td>2.206186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v2_summary_expert_one_shot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345043</td>\n",
       "      <td>1.226804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484376</td>\n",
       "      <td>1.329897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.262849</td>\n",
       "      <td>2.206186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    model  \\\n",
       "                                                            \n",
       "0                                             gpt_4o_mini   \n",
       "1    hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest   \n",
       "2                               llama3_2_3b_instruct_fp16   \n",
       "3                               llama3_2_3b_instruct_fp16   \n",
       "4  llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest   \n",
       "\n",
       "               prompt_version criterial_score embedding_cosine_distance  \\\n",
       "                                         mean                      mean   \n",
       "0           v3_summary_expert        0.494845                  0.118363   \n",
       "1           v3_summary_expert        0.030928                  0.276004   \n",
       "2  v2_summary_expert_one_shot        0.000000                  0.345043   \n",
       "3           v3_summary_expert        0.000000                  0.484376   \n",
       "4           v3_summary_expert        0.072165                  0.262849   \n",
       "\n",
       "      score  \n",
       "       mean  \n",
       "0  8.154639  \n",
       "1  2.206186  \n",
       "2  1.226804  \n",
       "3  1.329897  \n",
       "4  2.206186  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]>contex].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    .agg(['mean'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
