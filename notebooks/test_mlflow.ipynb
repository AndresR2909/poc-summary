{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31cfb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2309dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086a95a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readme.md         image-2.png       image-6.png       requirements.txt\n",
      "\u001b[30m\u001b[43mapp\u001b[m\u001b[m/              image-3.png       image.png\n",
      "\u001b[30m\u001b[43mdata\u001b[m\u001b[m/             image-4.png       \u001b[34mmlruns\u001b[m\u001b[m/\n",
      "image-1.png       image-5.png       \u001b[30m\u001b[43mnotebooks\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "616edb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimentos disponibles:\n",
      "1. report_summary_slms_vs_gpt4_1_reference\n"
     ]
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "# Cargamos experimentos que comiencen con \"eval_\"\n",
    "experiments = [\n",
    "    exp for exp in client.search_experiments() if exp.name.startswith(\"report_summary\")\n",
    "]\n",
    "\n",
    "if not experiments:\n",
    "   print(\"No hay experimentos disponibles.\")\n",
    "if experiments:\n",
    "    exp_names = [exp.name for exp in experiments]\n",
    "    print(\"Experimentos disponibles:\")\n",
    "    for i, exp in enumerate(exp_names):\n",
    "        print(f\"{i + 1}. {exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6e450ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 2436 ejecuciones registradas.\n"
     ]
    }
   ],
   "source": [
    "experiment = client.get_experiment_by_name(exp_names[0])\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\n",
    "        \"start_time DESC\",\n",
    "    ],\n",
    "    max_results=2500,\n",
    ")\n",
    "\n",
    "if not runs:\n",
    "    print(\"No hay ejecuciones registradas.\")\n",
    "else:\n",
    "    print(f\"Se encontraron {len(runs)} ejecuciones registradas.\")\n",
    "    # Recolectamos datos de cada run\n",
    "    data = []\n",
    "    for run in runs:\n",
    "        params = run.data.params\n",
    "        metrics = run.data.metrics\n",
    "        artifacts = client.list_artifacts(run.info.run_id)\n",
    "        list_artifacts = [artifact for artifact in artifacts]\n",
    "        dict_metrics = {\n",
    "            #'run_ID': run.info.run_id,\n",
    "            \"video_id\": params.get(\"video_id\"),\n",
    "            \"channel_name\": params.get(\"channel_name\"),\n",
    "            \"prompt_version\": params.get(\"prompt_version\"),\n",
    "            \"model\": params.get(\"llm_model\"),\n",
    "            # Métricas de evaluación\n",
    "            \"criterial_score\": metrics.get(\"criterial_score\", None),\n",
    "            \"embedding_cosine_distance\": metrics.get(\"embedding_cosine_distance\", None),\n",
    "            \"score\": metrics.get(\"score\", None),\n",
    "        }\n",
    "        data.append(dict_metrics)\n",
    "\n",
    "    # Creamos un dataframe con todos los datos\n",
    "    df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7dd65726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2436 entries, 0 to 2435\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   video_id                   2432 non-null   object \n",
      " 1   channel_name               2432 non-null   object \n",
      " 2   prompt_version             2432 non-null   object \n",
      " 3   model                      2432 non-null   object \n",
      " 4   criterial_score            2432 non-null   float64\n",
      " 5   embedding_cosine_distance  2432 non-null   float64\n",
      " 6   score                      2432 non-null   float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 133.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cab9c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221 entries, 0 to 220\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   video_id      221 non-null    object\n",
      " 1   channel_name  221 non-null    object\n",
      " 2   prompt        221 non-null    object\n",
      " 3   text          221 non-null    object\n",
      " 4   summary       221 non-null    object\n",
      " 5   slm_prompt    221 non-null    object\n",
      " 6   slm_summary   221 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 12.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_dataset_path = 'data/slm_summaries/test_slm_llama3_2_3b_instruct_fp16_v3_summary_expert.csv'\n",
    "df_test = pd.read_csv(test_dataset_path,sep=\";\")\n",
    "\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b52fb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "# Crear el codificador para llama-3.2 (usa 'cl100k_base' como aproximación)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Contar tokens en la columna 'slm_summary'\n",
    "df_test[\"slm_tokens\"] = df_test[\"text\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "sel_columns =['video_id', 'channel_name','slm_tokens']\n",
    "df_test_filter = df_test[sel_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5bfecde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2432.000000\n",
       "mean      7410.210526\n",
       "std       7621.480315\n",
       "min         38.000000\n",
       "25%       2381.000000\n",
       "50%       3661.000000\n",
       "75%      11824.000000\n",
       "max      31540.000000\n",
       "Name: slm_tokens, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined = pd.merge(df, df_test_filter, on=[\"channel_name\", \"video_id\"], how=\"inner\", suffixes=('', '_test'))\n",
    "df_joined['slm_tokens'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7435bd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th colspan=\"2\" halign=\"left\">criterial_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">embedding_cosine_distance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.601810</td>\n",
       "      <td>0.490636</td>\n",
       "      <td>0.100755</td>\n",
       "      <td>0.031121</td>\n",
       "      <td>8.479638</td>\n",
       "      <td>0.951454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.361991</td>\n",
       "      <td>0.481667</td>\n",
       "      <td>0.166664</td>\n",
       "      <td>0.063550</td>\n",
       "      <td>5.674208</td>\n",
       "      <td>2.272907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.171946</td>\n",
       "      <td>0.378190</td>\n",
       "      <td>0.197469</td>\n",
       "      <td>0.074781</td>\n",
       "      <td>4.506787</td>\n",
       "      <td>2.313242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>0.274143</td>\n",
       "      <td>0.202654</td>\n",
       "      <td>0.073806</td>\n",
       "      <td>4.325792</td>\n",
       "      <td>2.063253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.348057</td>\n",
       "      <td>0.224712</td>\n",
       "      <td>0.101414</td>\n",
       "      <td>3.330317</td>\n",
       "      <td>2.057013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.130631</td>\n",
       "      <td>0.337758</td>\n",
       "      <td>0.232396</td>\n",
       "      <td>0.111087</td>\n",
       "      <td>3.216216</td>\n",
       "      <td>2.083790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.162887</td>\n",
       "      <td>0.225847</td>\n",
       "      <td>0.062263</td>\n",
       "      <td>3.208145</td>\n",
       "      <td>1.615866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama_3_2_3B_Instruct_finetuned_bnb_nf4_dq_gguf_bf16_gguf_BF16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.090498</td>\n",
       "      <td>0.287545</td>\n",
       "      <td>0.246029</td>\n",
       "      <td>0.144780</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>2.057903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.217971</td>\n",
       "      <td>0.383360</td>\n",
       "      <td>0.265185</td>\n",
       "      <td>2.873303</td>\n",
       "      <td>1.952216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.162887</td>\n",
       "      <td>0.428200</td>\n",
       "      <td>0.216365</td>\n",
       "      <td>2.099548</td>\n",
       "      <td>1.670343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v2_summary_expert_one_shot</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.133614</td>\n",
       "      <td>0.309760</td>\n",
       "      <td>0.088487</td>\n",
       "      <td>1.642534</td>\n",
       "      <td>0.881012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             model  \\\n",
       "                                                                     \n",
       "0                                                      gpt_4o_mini   \n",
       "10           unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0   \n",
       "9                                                      phi4_latest   \n",
       "2                                        llama3_1_8b_instruct_fp16   \n",
       "8           llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest   \n",
       "1             hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest   \n",
       "4                                        llama3_2_3b_instruct_fp16   \n",
       "7   llama_3_2_3B_Instruct_finetuned_bnb_nf4_dq_gguf_bf16_gguf_BF16   \n",
       "3                                        llama3_1_8b_instruct_fp16   \n",
       "6                                        llama3_2_3b_instruct_fp16   \n",
       "5                                        llama3_2_3b_instruct_fp16   \n",
       "\n",
       "                prompt_version criterial_score            \\\n",
       "                                          mean       std   \n",
       "0            v3_summary_expert        0.601810  0.490636   \n",
       "10           v3_summary_expert        0.361991  0.481667   \n",
       "9            v3_summary_expert        0.171946  0.378190   \n",
       "2   v1_summary_expert_one_shot        0.081448  0.274143   \n",
       "8            v3_summary_expert        0.140271  0.348057   \n",
       "1            v3_summary_expert        0.130631  0.337758   \n",
       "4   v1_summary_expert_one_shot        0.027149  0.162887   \n",
       "7            v3_summary_expert        0.090498  0.287545   \n",
       "3            v3_summary_expert        0.049774  0.217971   \n",
       "6            v3_summary_expert        0.027149  0.162887   \n",
       "5   v2_summary_expert_one_shot        0.018100  0.133614   \n",
       "\n",
       "   embedding_cosine_distance               score            \n",
       "                        mean       std      mean       std  \n",
       "0                   0.100755  0.031121  8.479638  0.951454  \n",
       "10                  0.166664  0.063550  5.674208  2.272907  \n",
       "9                   0.197469  0.074781  4.506787  2.313242  \n",
       "2                   0.202654  0.073806  4.325792  2.063253  \n",
       "8                   0.224712  0.101414  3.330317  2.057013  \n",
       "1                   0.232396  0.111087  3.216216  2.083790  \n",
       "4                   0.225847  0.062263  3.208145  1.615866  \n",
       "7                   0.246029  0.144780  3.076923  2.057903  \n",
       "3                   0.383360  0.265185  2.873303  1.952216  \n",
       "6                   0.428200  0.216365  2.099548  1.670343  \n",
       "5                   0.309760  0.088487  1.642534  0.881012  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df.drop(columns=[\"video_id\", \"channel_name\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    #.agg(['mean','median','std','min','max'])\n",
    "    .agg(['mean','std'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Ordenar de mayor a menor por el score medio\n",
    "df_grouped_1 = df_grouped_1.sort_values(('score', 'mean'), ascending=False)\n",
    "\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5609f04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrando por Chunk Size menor a 3661\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th colspan=\"2\" halign=\"left\">criterial_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">embedding_cosine_distance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.459141</td>\n",
       "      <td>0.084842</td>\n",
       "      <td>0.024657</td>\n",
       "      <td>8.774775</td>\n",
       "      <td>0.598250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.504505</td>\n",
       "      <td>0.502247</td>\n",
       "      <td>0.134610</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>6.972973</td>\n",
       "      <td>1.904347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.459141</td>\n",
       "      <td>0.162437</td>\n",
       "      <td>0.069192</td>\n",
       "      <td>5.702703</td>\n",
       "      <td>2.399222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.370271</td>\n",
       "      <td>0.176965</td>\n",
       "      <td>0.081065</td>\n",
       "      <td>5.315315</td>\n",
       "      <td>2.211466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.413530</td>\n",
       "      <td>0.188573</td>\n",
       "      <td>0.103758</td>\n",
       "      <td>4.378378</td>\n",
       "      <td>2.248450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.225225</td>\n",
       "      <td>0.419625</td>\n",
       "      <td>0.183678</td>\n",
       "      <td>0.089690</td>\n",
       "      <td>4.243243</td>\n",
       "      <td>2.374930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.227150</td>\n",
       "      <td>0.203421</td>\n",
       "      <td>0.056505</td>\n",
       "      <td>3.909910</td>\n",
       "      <td>1.871069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama_3_2_3B_Instruct_finetuned_bnb_nf4_dq_gguf_bf16_gguf_BF16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.352829</td>\n",
       "      <td>0.214369</td>\n",
       "      <td>0.135610</td>\n",
       "      <td>3.900901</td>\n",
       "      <td>2.426951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.287609</td>\n",
       "      <td>0.314948</td>\n",
       "      <td>0.250493</td>\n",
       "      <td>3.756757</td>\n",
       "      <td>2.265216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.227150</td>\n",
       "      <td>0.371499</td>\n",
       "      <td>0.226478</td>\n",
       "      <td>2.855856</td>\n",
       "      <td>2.021911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v2_summary_expert_one_shot</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>0.187225</td>\n",
       "      <td>0.280092</td>\n",
       "      <td>0.075428</td>\n",
       "      <td>2.018018</td>\n",
       "      <td>1.035567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             model  \\\n",
       "                                                                     \n",
       "0                                                      gpt_4o_mini   \n",
       "10           unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0   \n",
       "9                                                      phi4_latest   \n",
       "2                                        llama3_1_8b_instruct_fp16   \n",
       "8           llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest   \n",
       "1             hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest   \n",
       "4                                        llama3_2_3b_instruct_fp16   \n",
       "7   llama_3_2_3B_Instruct_finetuned_bnb_nf4_dq_gguf_bf16_gguf_BF16   \n",
       "3                                        llama3_1_8b_instruct_fp16   \n",
       "6                                        llama3_2_3b_instruct_fp16   \n",
       "5                                        llama3_2_3b_instruct_fp16   \n",
       "\n",
       "                prompt_version criterial_score            \\\n",
       "                                          mean       std   \n",
       "0            v3_summary_expert        0.702703  0.459141   \n",
       "10           v3_summary_expert        0.504505  0.502247   \n",
       "9            v3_summary_expert        0.297297  0.459141   \n",
       "2   v1_summary_expert_one_shot        0.162162  0.370271   \n",
       "8            v3_summary_expert        0.216216  0.413530   \n",
       "1            v3_summary_expert        0.225225  0.419625   \n",
       "4   v1_summary_expert_one_shot        0.054054  0.227150   \n",
       "7            v3_summary_expert        0.144144  0.352829   \n",
       "3            v3_summary_expert        0.090090  0.287609   \n",
       "6            v3_summary_expert        0.054054  0.227150   \n",
       "5   v2_summary_expert_one_shot        0.036036  0.187225   \n",
       "\n",
       "   embedding_cosine_distance               score            \n",
       "                        mean       std      mean       std  \n",
       "0                   0.084842  0.024657  8.774775  0.598250  \n",
       "10                  0.134610  0.054517  6.972973  1.904347  \n",
       "9                   0.162437  0.069192  5.702703  2.399222  \n",
       "2                   0.176965  0.081065  5.315315  2.211466  \n",
       "8                   0.188573  0.103758  4.378378  2.248450  \n",
       "1                   0.183678  0.089690  4.243243  2.374930  \n",
       "4                   0.203421  0.056505  3.909910  1.871069  \n",
       "7                   0.214369  0.135610  3.900901  2.426951  \n",
       "3                   0.314948  0.250493  3.756757  2.265216  \n",
       "6                   0.371499  0.226478  2.855856  2.021911  \n",
       "5                   0.280092  0.075428  2.018018  1.035567  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contex = 3661 # 50% de text block_size=8192 or max_seq_length: 4096\n",
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "print(f\"Filtrando por Chunk Size menor a {contex}\")\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]<=contex].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    #.agg(['mean','median','std','min','max'])\n",
    "    .agg(['mean','std'])\n",
    "    .reset_index()\n",
    ")\n",
    "df_grouped_1 = df_grouped_1.sort_values(('score', 'mean'), ascending=False)\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd0ed122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrando por Chunk Size menor a 11824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th colspan=\"2\" halign=\"left\">criterial_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">embedding_cosine_distance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.644578</td>\n",
       "      <td>0.480089</td>\n",
       "      <td>0.091969</td>\n",
       "      <td>0.028167</td>\n",
       "      <td>8.668675</td>\n",
       "      <td>0.664134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.421687</td>\n",
       "      <td>0.495323</td>\n",
       "      <td>0.152463</td>\n",
       "      <td>0.059531</td>\n",
       "      <td>6.295181</td>\n",
       "      <td>2.115650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.222892</td>\n",
       "      <td>0.417445</td>\n",
       "      <td>0.182883</td>\n",
       "      <td>0.072190</td>\n",
       "      <td>5.084337</td>\n",
       "      <td>2.299960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>0.311868</td>\n",
       "      <td>0.193080</td>\n",
       "      <td>0.076589</td>\n",
       "      <td>4.753012</td>\n",
       "      <td>2.118996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.364548</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>0.099414</td>\n",
       "      <td>3.789157</td>\n",
       "      <td>2.117203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.173653</td>\n",
       "      <td>0.379950</td>\n",
       "      <td>0.214896</td>\n",
       "      <td>0.105946</td>\n",
       "      <td>3.646707</td>\n",
       "      <td>2.203715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.187215</td>\n",
       "      <td>0.216847</td>\n",
       "      <td>0.059995</td>\n",
       "      <td>3.518072</td>\n",
       "      <td>1.722306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama_3_2_3B_Instruct_finetuned_bnb_nf4_dq_gguf_bf16_gguf_BF16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.114458</td>\n",
       "      <td>0.319330</td>\n",
       "      <td>0.223846</td>\n",
       "      <td>0.126848</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.173532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.066265</td>\n",
       "      <td>0.249497</td>\n",
       "      <td>0.324389</td>\n",
       "      <td>0.240661</td>\n",
       "      <td>3.301205</td>\n",
       "      <td>2.028494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.187215</td>\n",
       "      <td>0.415536</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>2.385542</td>\n",
       "      <td>1.821297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v2_summary_expert_one_shot</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.153812</td>\n",
       "      <td>0.291922</td>\n",
       "      <td>0.080017</td>\n",
       "      <td>1.855422</td>\n",
       "      <td>0.922875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             model  \\\n",
       "                                                                     \n",
       "0                                                      gpt_4o_mini   \n",
       "10           unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0   \n",
       "9                                                      phi4_latest   \n",
       "2                                        llama3_1_8b_instruct_fp16   \n",
       "8           llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest   \n",
       "1             hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest   \n",
       "4                                        llama3_2_3b_instruct_fp16   \n",
       "7   llama_3_2_3B_Instruct_finetuned_bnb_nf4_dq_gguf_bf16_gguf_BF16   \n",
       "3                                        llama3_1_8b_instruct_fp16   \n",
       "6                                        llama3_2_3b_instruct_fp16   \n",
       "5                                        llama3_2_3b_instruct_fp16   \n",
       "\n",
       "                prompt_version criterial_score            \\\n",
       "                                          mean       std   \n",
       "0            v3_summary_expert        0.644578  0.480089   \n",
       "10           v3_summary_expert        0.421687  0.495323   \n",
       "9            v3_summary_expert        0.222892  0.417445   \n",
       "2   v1_summary_expert_one_shot        0.108434  0.311868   \n",
       "8            v3_summary_expert        0.156627  0.364548   \n",
       "1            v3_summary_expert        0.173653  0.379950   \n",
       "4   v1_summary_expert_one_shot        0.036145  0.187215   \n",
       "7            v3_summary_expert        0.114458  0.319330   \n",
       "3            v3_summary_expert        0.066265  0.249497   \n",
       "6            v3_summary_expert        0.036145  0.187215   \n",
       "5   v2_summary_expert_one_shot        0.024096  0.153812   \n",
       "\n",
       "   embedding_cosine_distance               score            \n",
       "                        mean       std      mean       std  \n",
       "0                   0.091969  0.028167  8.668675  0.664134  \n",
       "10                  0.152463  0.059531  6.295181  2.115650  \n",
       "9                   0.182883  0.072190  5.084337  2.299960  \n",
       "2                   0.193080  0.076589  4.753012  2.118996  \n",
       "8                   0.206393  0.099414  3.789157  2.117203  \n",
       "1                   0.214896  0.105946  3.646707  2.203715  \n",
       "4                   0.216847  0.059995  3.518072  1.722306  \n",
       "7                   0.223846  0.126848  3.500000  2.173532  \n",
       "3                   0.324389  0.240661  3.301205  2.028494  \n",
       "6                   0.415536  0.225690  2.385542  1.821297  \n",
       "5                   0.291922  0.080017  1.855422  0.922875  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contex = 11824 # block_size=8192 or max_seq_length: 4096\n",
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "print(f\"Filtrando por Chunk Size menor a {contex}\")\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]<=contex].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "     #.agg(['mean','median','std','min','max'])\n",
    "    .agg(['mean','std'])\n",
    "    .reset_index()\n",
    ")\n",
    "df_grouped_1 = df_grouped_1.sort_values(('score', 'mean'), ascending=False)\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de1c5fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrando por Chunk Size menor a 6000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th colspan=\"2\" halign=\"left\">criterial_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">embedding_cosine_distance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.480721</td>\n",
       "      <td>0.088485</td>\n",
       "      <td>0.024992</td>\n",
       "      <td>8.688312</td>\n",
       "      <td>0.661939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.422078</td>\n",
       "      <td>0.495502</td>\n",
       "      <td>0.148719</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>6.350649</td>\n",
       "      <td>2.119108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.424606</td>\n",
       "      <td>0.177593</td>\n",
       "      <td>0.069875</td>\n",
       "      <td>5.227273</td>\n",
       "      <td>2.302379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.322329</td>\n",
       "      <td>0.188707</td>\n",
       "      <td>0.075984</td>\n",
       "      <td>4.831169</td>\n",
       "      <td>2.153596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.162338</td>\n",
       "      <td>0.369963</td>\n",
       "      <td>0.202799</td>\n",
       "      <td>0.099172</td>\n",
       "      <td>3.889610</td>\n",
       "      <td>2.113021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.167742</td>\n",
       "      <td>0.374848</td>\n",
       "      <td>0.209754</td>\n",
       "      <td>0.105069</td>\n",
       "      <td>3.716129</td>\n",
       "      <td>2.232449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.194133</td>\n",
       "      <td>0.214699</td>\n",
       "      <td>0.059210</td>\n",
       "      <td>3.590909</td>\n",
       "      <td>1.758689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama_3_2_3B_Instruct_finetuned_bnb_nf4_dq_gguf_bf16_gguf_BF16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>0.329942</td>\n",
       "      <td>0.223411</td>\n",
       "      <td>0.129895</td>\n",
       "      <td>3.584416</td>\n",
       "      <td>2.227872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.247215</td>\n",
       "      <td>0.312951</td>\n",
       "      <td>0.232394</td>\n",
       "      <td>3.396104</td>\n",
       "      <td>2.056136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.194133</td>\n",
       "      <td>0.404055</td>\n",
       "      <td>0.224903</td>\n",
       "      <td>2.480519</td>\n",
       "      <td>1.854938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v2_summary_expert_one_shot</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.159577</td>\n",
       "      <td>0.289906</td>\n",
       "      <td>0.082370</td>\n",
       "      <td>1.902597</td>\n",
       "      <td>0.934240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             model  \\\n",
       "                                                                     \n",
       "0                                                      gpt_4o_mini   \n",
       "10           unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0   \n",
       "9                                                      phi4_latest   \n",
       "2                                        llama3_1_8b_instruct_fp16   \n",
       "8           llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest   \n",
       "1             hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest   \n",
       "4                                        llama3_2_3b_instruct_fp16   \n",
       "7   llama_3_2_3B_Instruct_finetuned_bnb_nf4_dq_gguf_bf16_gguf_BF16   \n",
       "3                                        llama3_1_8b_instruct_fp16   \n",
       "6                                        llama3_2_3b_instruct_fp16   \n",
       "5                                        llama3_2_3b_instruct_fp16   \n",
       "\n",
       "                prompt_version criterial_score            \\\n",
       "                                          mean       std   \n",
       "0            v3_summary_expert        0.642857  0.480721   \n",
       "10           v3_summary_expert        0.422078  0.495502   \n",
       "9            v3_summary_expert        0.233766  0.424606   \n",
       "2   v1_summary_expert_one_shot        0.116883  0.322329   \n",
       "8            v3_summary_expert        0.162338  0.369963   \n",
       "1            v3_summary_expert        0.167742  0.374848   \n",
       "4   v1_summary_expert_one_shot        0.038961  0.194133   \n",
       "7            v3_summary_expert        0.123377  0.329942   \n",
       "3            v3_summary_expert        0.064935  0.247215   \n",
       "6            v3_summary_expert        0.038961  0.194133   \n",
       "5   v2_summary_expert_one_shot        0.025974  0.159577   \n",
       "\n",
       "   embedding_cosine_distance               score            \n",
       "                        mean       std      mean       std  \n",
       "0                   0.088485  0.024992  8.688312  0.661939  \n",
       "10                  0.148719  0.056783  6.350649  2.119108  \n",
       "9                   0.177593  0.069875  5.227273  2.302379  \n",
       "2                   0.188707  0.075984  4.831169  2.153596  \n",
       "8                   0.202799  0.099172  3.889610  2.113021  \n",
       "1                   0.209754  0.105069  3.716129  2.232449  \n",
       "4                   0.214699  0.059210  3.590909  1.758689  \n",
       "7                   0.223411  0.129895  3.584416  2.227872  \n",
       "3                   0.312951  0.232394  3.396104  2.056136  \n",
       "6                   0.404055  0.224903  2.480519  1.854938  \n",
       "5                   0.289906  0.082370  1.902597  0.934240  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contex = 6000 # valor maximo promedio de los ultimos años sin USACRIPTOMONEDAS\n",
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "print(f\"Filtrando por Chunk Size menor a {contex}\")\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]<=contex].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    #.agg(['mean','median','std','min','max'])\n",
    "    .agg(['mean','std'])\n",
    "    .reset_index()\n",
    ")\n",
    "df_grouped_1 = df_grouped_1.sort_values(('score', 'mean'), ascending=False)\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7504820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th colspan=\"2\" halign=\"left\">criterial_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">embedding_cosine_distance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_4o_mini</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.503718</td>\n",
       "      <td>0.128956</td>\n",
       "      <td>0.024935</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.290994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.419989</td>\n",
       "      <td>0.207909</td>\n",
       "      <td>0.059236</td>\n",
       "      <td>4.119403</td>\n",
       "      <td>1.813438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234713</td>\n",
       "      <td>0.057242</td>\n",
       "      <td>3.164179</td>\n",
       "      <td>1.213522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phi4_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.171460</td>\n",
       "      <td>0.243156</td>\n",
       "      <td>0.065433</td>\n",
       "      <td>2.850746</td>\n",
       "      <td>1.246252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v1_summary_expert_one_shot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251470</td>\n",
       "      <td>0.061958</td>\n",
       "      <td>2.328358</td>\n",
       "      <td>0.636945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.208373</td>\n",
       "      <td>0.284777</td>\n",
       "      <td>0.107578</td>\n",
       "      <td>2.059701</td>\n",
       "      <td>0.982893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.287694</td>\n",
       "      <td>0.275078</td>\n",
       "      <td>0.088247</td>\n",
       "      <td>2.044776</td>\n",
       "      <td>1.160366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama_3_2_3B_Instruct_finetuned_bnb_nf4_dq_gguf_bf16_gguf_BF16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.122169</td>\n",
       "      <td>0.298016</td>\n",
       "      <td>0.163767</td>\n",
       "      <td>1.910448</td>\n",
       "      <td>0.792605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3_1_8b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.122169</td>\n",
       "      <td>0.545195</td>\n",
       "      <td>0.266566</td>\n",
       "      <td>1.671642</td>\n",
       "      <td>0.894225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v3_summary_expert</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483698</td>\n",
       "      <td>0.185209</td>\n",
       "      <td>1.223881</td>\n",
       "      <td>0.454636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3_2_3b_instruct_fp16</td>\n",
       "      <td>v2_summary_expert_one_shot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355397</td>\n",
       "      <td>0.085659</td>\n",
       "      <td>1.044776</td>\n",
       "      <td>0.208373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             model  \\\n",
       "                                                                     \n",
       "0                                                      gpt_4o_mini   \n",
       "10           unsloth_Meta_Llama_3_1_8B_Instruct_bnb_4bit_gguf_Q8_0   \n",
       "2                                        llama3_1_8b_instruct_fp16   \n",
       "9                                                      phi4_latest   \n",
       "4                                        llama3_2_3b_instruct_fp16   \n",
       "1             hf_llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_latest   \n",
       "8           llama_3_2_3b_finetuned_qlora_bnb_nf42_gguf_q8_0_latest   \n",
       "7   llama_3_2_3B_Instruct_finetuned_bnb_nf4_dq_gguf_bf16_gguf_BF16   \n",
       "3                                        llama3_1_8b_instruct_fp16   \n",
       "6                                        llama3_2_3b_instruct_fp16   \n",
       "5                                        llama3_2_3b_instruct_fp16   \n",
       "\n",
       "                prompt_version criterial_score            \\\n",
       "                                          mean       std   \n",
       "0            v3_summary_expert        0.507463  0.503718   \n",
       "10           v3_summary_expert        0.223881  0.419989   \n",
       "2   v1_summary_expert_one_shot        0.000000  0.000000   \n",
       "9            v3_summary_expert        0.029851  0.171460   \n",
       "4   v1_summary_expert_one_shot        0.000000  0.000000   \n",
       "1            v3_summary_expert        0.044776  0.208373   \n",
       "8            v3_summary_expert        0.089552  0.287694   \n",
       "7            v3_summary_expert        0.014925  0.122169   \n",
       "3            v3_summary_expert        0.014925  0.122169   \n",
       "6            v3_summary_expert        0.000000  0.000000   \n",
       "5   v2_summary_expert_one_shot        0.000000  0.000000   \n",
       "\n",
       "   embedding_cosine_distance               score            \n",
       "                        mean       std      mean       std  \n",
       "0                   0.128956  0.024935  8.000000  1.290994  \n",
       "10                  0.207909  0.059236  4.119403  1.813438  \n",
       "2                   0.234713  0.057242  3.164179  1.213522  \n",
       "9                   0.243156  0.065433  2.850746  1.246252  \n",
       "4                   0.251470  0.061958  2.328358  0.636945  \n",
       "1                   0.284777  0.107578  2.059701  0.982893  \n",
       "8                   0.275078  0.088247  2.044776  1.160366  \n",
       "7                   0.298016  0.163767  1.910448  0.792605  \n",
       "3                   0.545195  0.266566  1.671642  0.894225  \n",
       "6                   0.483698  0.185209  1.223881  0.454636  \n",
       "5                   0.355397  0.085659  1.044776  0.208373  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrar y agrupar dataset por Chunk Size y Prompt, sacar promedio del resto de columnas\n",
    "# Agrupar por 'model' y 'prompt_version' y calcular estadísticas agregadas\n",
    "df_grouped_1 = (\n",
    "    df_joined[df_joined[\"slm_tokens\"]>contex].drop(columns=[\"video_id\", \"channel_name\",\"slm_tokens\"])\n",
    "    .groupby([\"model\", \"prompt_version\"])\n",
    "    #.agg(['mean','median','std','min','max'])\n",
    "    .agg(['mean','std'])\n",
    "    .reset_index()\n",
    ")\n",
    "df_grouped_1 = df_grouped_1.sort_values(('score', 'mean'), ascending=False)\n",
    "# Para mostrar el contenido completo del DataFrame sin truncar columnas o filas\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(df_grouped_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
