{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create videos transcripts summaries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m\u001b[43mapp\u001b[m\u001b[m/              \u001b[30m\u001b[43mdata\u001b[m\u001b[m/             \u001b[30m\u001b[43mnotebooks\u001b[m\u001b[m/        requirements.txt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrestrepo/Documents/repos_personal/poc-summary/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.storage.data_lake_pandas import DataLakePandas\n",
    "from app.llm.llm import SummaryLlm\n",
    "from app.preprocessing.summary import SummaryProccesing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from huggingface_hub import login\n",
    "from datasets import Dataset,load_dataset, DatasetDict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cargar datos procesados de zona curated del datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_pandas = DataLakePandas()\n",
    "\n",
    "years = [0,2014,2019,2020,2021,2022,2023,2024,2025]\n",
    "\n",
    "for year in years:\n",
    "    df_curated = dl_pandas.read_dataframe_from_parquet(\n",
    "        container_name='curated',\n",
    "        file_name=f\"youtube_data/youtube_data_{year}\",\n",
    "        filter=None,\n",
    "    )\n",
    "    df_curated['month'] = pd.to_datetime(df_curated['publish_date']).dt.month\n",
    "    df_curated['year'] = year\n",
    "    if year == years[0]:\n",
    "        df_all = df_curated\n",
    "    else:\n",
    "        df_all = pd.concat([df_all, df_curated], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2290 entries, 0 to 2294\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   channel_name      2290 non-null   object        \n",
      " 1   video_id          2290 non-null   object        \n",
      " 2   source            2290 non-null   object        \n",
      " 3   publish_date      1675 non-null   datetime64[ns]\n",
      " 4   duration          2290 non-null   float64       \n",
      " 5   last_update_date  2290 non-null   object        \n",
      " 6   title             2290 non-null   object        \n",
      " 7   text              2290 non-null   object        \n",
      " 8   year              2290 non-null   int64         \n",
      " 9   month             2290 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(7)\n",
      "memory usage: 196.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fechas de publicación minima y maxima (Timestamp('2014-09-03 00:00:00'), Timestamp('2025-04-17 00:00:00'))\n"
     ]
    }
   ],
   "source": [
    "print(f\"fechas de publicación minima y maxima {df_all[\"publish_date\"].min(),df_all[\"publish_date\"].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resumir documentos y analisis de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_processing = SummaryProccesing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>video_id</th>\n",
       "      <th>source</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>number_of_tokenks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bolsas hoy | Invierte y Crece</td>\n",
       "      <td>MEFcIWdwoEI</td>\n",
       "      <td>https://www.youtube.com/watch?v=MEFcIWdwoEI</td>\n",
       "      <td>NaT</td>\n",
       "      <td>822.0</td>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>sp500 y oro alcanzan sus objetivos proyectados...</td>\n",
       "      <td>sp500 y oro alcanzan sus objetivos proyectados...</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsas hoy | Invierte y Crece</td>\n",
       "      <td>yQdTS2296V8</td>\n",
       "      <td>https://www.youtube.com/watch?v=yQdTS2296V8</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>la fed te hace perder dinero porque  no puede ...</td>\n",
       "      <td>la fed te hace perder dinero porque no puede p...</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>3639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bolsas hoy | Invierte y Crece</td>\n",
       "      <td>5uDK19-gLkw</td>\n",
       "      <td>https://www.youtube.com/watch?v=5uDK19-gLkw</td>\n",
       "      <td>NaT</td>\n",
       "      <td>907.0</td>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>máximos históricos del sp 500 son una cuestión...</td>\n",
       "      <td>máximos históricos del sp 500 son una cuestión...</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>2847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bolsas hoy | Invierte y Crece</td>\n",
       "      <td>dm-GKckZQG4</td>\n",
       "      <td>https://www.youtube.com/watch?v=dm-GKckZQG4</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>mejor aprender a saber qué hacer en vez de bus...</td>\n",
       "      <td>mejor aprender a saber qué hacer en vez de bus...</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bolsas hoy | Invierte y Crece</td>\n",
       "      <td>n4ZxNi2TjaY</td>\n",
       "      <td>https://www.youtube.com/watch?v=n4ZxNi2TjaY</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>nuevas proyecciones ya que los planes se han e...</td>\n",
       "      <td>nuevas proyecciones ya que los planes se han e...</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>3221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     channel_name     video_id  \\\n",
       "0  Bolsas hoy | Invierte y Crece   MEFcIWdwoEI   \n",
       "1  Bolsas hoy | Invierte y Crece   yQdTS2296V8   \n",
       "2  Bolsas hoy | Invierte y Crece   5uDK19-gLkw   \n",
       "3  Bolsas hoy | Invierte y Crece   dm-GKckZQG4   \n",
       "4  Bolsas hoy | Invierte y Crece   n4ZxNi2TjaY   \n",
       "\n",
       "                                        source publish_date  duration  \\\n",
       "0  https://www.youtube.com/watch?v=MEFcIWdwoEI          NaT     822.0   \n",
       "1  https://www.youtube.com/watch?v=yQdTS2296V8          NaT    1251.0   \n",
       "2  https://www.youtube.com/watch?v=5uDK19-gLkw          NaT     907.0   \n",
       "3  https://www.youtube.com/watch?v=dm-GKckZQG4          NaT    1142.0   \n",
       "4  https://www.youtube.com/watch?v=n4ZxNi2TjaY          NaT    1055.0   \n",
       "\n",
       "  last_update_date                                              title  \\\n",
       "0       2025-03-10  sp500 y oro alcanzan sus objetivos proyectados...   \n",
       "1       2025-03-10  la fed te hace perder dinero porque  no puede ...   \n",
       "2       2025-03-10  máximos históricos del sp 500 son una cuestión...   \n",
       "3       2025-03-10  mejor aprender a saber qué hacer en vez de bus...   \n",
       "4       2025-03-10  nuevas proyecciones ya que los planes se han e...   \n",
       "\n",
       "                                                text  year month  \\\n",
       "0  sp500 y oro alcanzan sus objetivos proyectados...     0    01   \n",
       "1  la fed te hace perder dinero porque no puede p...     0    01   \n",
       "2  máximos históricos del sp 500 son una cuestión...     0    01   \n",
       "3  mejor aprender a saber qué hacer en vez de bus...     0    01   \n",
       "4  nuevas proyecciones ya que los planes se han e...     0    01   \n",
       "\n",
       "   number_of_tokenks  \n",
       "0               2389  \n",
       "1               3639  \n",
       "2               2847  \n",
       "3               3380  \n",
       "4               3221  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = summary_processing.add_column_count_tokens(df_all)\n",
    "new_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentil 95 del numero de tokens en transcripciones videos por canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_name\n",
       "ARENA ALFA                         5697.60\n",
       "Bitcoin hoy                        5793.00\n",
       "Bolsas hoy | Esteban Pérez         5434.50\n",
       "Bolsas hoy | Invierte y Crece      9193.45\n",
       "Esteban Perez                      4774.70\n",
       "USACRYPTONOTICIAS                 22404.00\n",
       "Name: number_of_tokenks, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentiles_95 = new_dataset.groupby(\"channel_name\")[\"number_of_tokenks\"].quantile(0.95)\n",
    "percentiles_95\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores maximos y minimos de tokens en transcripciones videos por canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARENA ALFA</th>\n",
       "      <td>162</td>\n",
       "      <td>12280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bitcoin hoy</th>\n",
       "      <td>1073</td>\n",
       "      <td>6012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bolsas hoy | Esteban Pérez</th>\n",
       "      <td>687</td>\n",
       "      <td>5835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bolsas hoy | Invierte y Crece</th>\n",
       "      <td>193</td>\n",
       "      <td>13594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Esteban Perez</th>\n",
       "      <td>156</td>\n",
       "      <td>11955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USACRYPTONOTICIAS</th>\n",
       "      <td>34</td>\n",
       "      <td>42638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 min    max\n",
       "channel_name                               \n",
       "ARENA ALFA                       162  12280\n",
       "Bitcoin hoy                     1073   6012\n",
       "Bolsas hoy | Esteban Pérez       687   5835\n",
       "Bolsas hoy | Invierte y Crece    193  13594\n",
       "Esteban Perez                    156  11955\n",
       "USACRYPTONOTICIAS                 34  42638"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Percentil 95 del numero de tokens por canal\n",
    "min_max_tokens = new_dataset.groupby(\"channel_name\")[\"number_of_tokenks\"].agg([\"min\", \"max\"])\n",
    "min_max_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resumir documentos por canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_name\n",
       "ARENA ALFA                        145\n",
       "Bitcoin hoy                        66\n",
       "Bolsas hoy | Esteban Pérez         26\n",
       "Bolsas hoy | Invierte y Crece     290\n",
       "Esteban Perez                     812\n",
       "USACRYPTONOTICIAS                 951\n",
       "Name: video_id, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_por_canal = new_dataset.groupby(\"channel_name\")[\"video_id\"].count()\n",
    "videos_por_canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"type\": \"openai\",\n",
    "    \"model\":'gpt-4o-2024-08-06',\n",
    "    \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"temperature\": 0,\n",
    "    \"max_completion_tokens\": 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-2024-08-06'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumary_model = SummaryLlm(config)\n",
    "sumary_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eres un experto de trading y analisis de mercado.\n",
      "Tu trabajo consiste en elaborar un informe con los topicos mas importantes del siguiente texto:\n",
      "------------\n",
      "{context}\n",
      "------------\n",
      "Comience el resumen final con una \"Introducción\" que ofrezca una visión general del tema, seguido\n",
      "por los puntos más importantes (\"Bullet Points\"). Termina el resumen con una conclusión.\n",
      "**Además, extrae los activos mencionados para invertir y crea una lista separada de los mismos.**\n",
      "Respuesta:\n"
     ]
    }
   ],
   "source": [
    "print(sumary_model.summary_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los nombres únicos de los canales\n",
    "channel_names = new_dataset[\"channel_name\"].unique()\n",
    "\n",
    "# Crear un diccionario para almacenar los resúmenes por canal\n",
    "summaries_by_channel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando resumen para el canal: USACRYPTONOTICIAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing texts: 100%|██████████| 1043/1043 [3:05:42<00:00, 10.68s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando resumen para el canal: Esteban Perez \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing texts: 100%|██████████| 812/812 [2:00:00<00:00,  8.87s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando resumen para el canal: ARENA ALFA \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing texts: 100%|██████████| 150/150 [20:50<00:00,  8.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando resumen para el canal: Bitcoin hoy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing texts: 100%|██████████| 132/132 [18:34<00:00,  8.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando resumen para el canal: Bolsas hoy | Esteban Pérez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing texts: 100%|██████████| 52/52 [06:33<00:00,  7.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generar resumen para cada canal\n",
    "for channel_name in channel_names:\n",
    "    print(f\"Generando resumen para el canal: {channel_name}\")\n",
    "    df_channel = new_dataset[new_dataset[\"channel_name\"] == channel_name]\n",
    "    summaries_df = summary_processing.summarize_dataframe(\n",
    "        df_channel, llm=sumary_model, sleep_time=1\n",
    "    )\n",
    "    summaries_df.to_csv(\n",
    "        f\"data/summaries/{channel_name}_summary.csv\", sep=\";\", index=False\n",
    "    )\n",
    "    summaries_by_channel.append(summaries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summaries_df = pd.concat(summaries_by_channel, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summaries_df.drop_duplicates(subset=[\"video_id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   channel_name       2225 non-null   object        \n",
      " 1   video_id           2225 non-null   object        \n",
      " 2   source             2225 non-null   object        \n",
      " 3   publish_date       1610 non-null   datetime64[ns]\n",
      " 4   duration           2225 non-null   float64       \n",
      " 5   last_update_date   2225 non-null   object        \n",
      " 6   title              2225 non-null   object        \n",
      " 7   text               2225 non-null   object        \n",
      " 8   year               2225 non-null   int64         \n",
      " 9   month              2225 non-null   object        \n",
      " 10  number_of_tokenks  2225 non-null   int64         \n",
      " 11  prompt             2225 non-null   object        \n",
      " 12  summary            2225 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(9)\n",
      "memory usage: 226.1+ KB\n"
     ]
    }
   ],
   "source": [
    "all_summaries_df.reset_index(drop=True, inplace=True)\n",
    "all_summaries_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summaries_df = summary_processing.extract_key_terms_from_df(all_summaries_df, column_name='summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   channel_name       2225 non-null   object        \n",
      " 1   video_id           2225 non-null   object        \n",
      " 2   source             2225 non-null   object        \n",
      " 3   publish_date       1610 non-null   datetime64[ns]\n",
      " 4   duration           2225 non-null   float64       \n",
      " 5   last_update_date   2225 non-null   object        \n",
      " 6   title              2225 non-null   object        \n",
      " 7   text               2225 non-null   object        \n",
      " 8   year               2225 non-null   int64         \n",
      " 9   month              2225 non-null   object        \n",
      " 10  number_of_tokenks  2225 non-null   int64         \n",
      " 11  prompt             2225 non-null   object        \n",
      " 12  summary            2225 non-null   object        \n",
      " 13  key_terms          2212 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(10)\n",
      "memory usage: 243.5+ KB\n"
     ]
    }
   ],
   "source": [
    "all_summaries_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>key_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bolsas hoy | Invierte y Crece</td>\n",
       "      <td>[S&amp;P 500,  Nasdaq,  DAX,  Eurostoxx,  Oro,  Cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsas hoy | Invierte y Crece</td>\n",
       "      <td>[S&amp;P 500 (SPX),  ETF SPY,  Nasdaq,  ETF Triple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bolsas hoy | Invierte y Crece</td>\n",
       "      <td>[S&amp;P 500,  Nasdaq,  Bitcoin,  Oro,  Acciones t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bolsas hoy | Invierte y Crece</td>\n",
       "      <td>[Inditex, Alphabet (Google), Walt Disney, Acci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bolsas hoy | Invierte y Crece</td>\n",
       "      <td>[IBEX, DAX, Eurostoxx, S&amp;P 500, Nasdaq, Bitcoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>Bolsas hoy | Esteban Pérez</td>\n",
       "      <td>[Inditex, AXA, Mapfre, Bering, Sirius, Pfizer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Bolsas hoy | Esteban Pérez</td>\n",
       "      <td>[Charter Communications (CHTR),  Lemonade (LMN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Bolsas hoy | Esteban Pérez</td>\n",
       "      <td>[Charter Communications (CHTR)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>Bolsas hoy | Esteban Pérez</td>\n",
       "      <td>[S&amp;P 500, Nasdaq, Oro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Bolsas hoy | Esteban Pérez</td>\n",
       "      <td>[Oro, Bonos a 2 y 10 años, Acciones (en genera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        channel_name  \\\n",
       "0     Bolsas hoy | Invierte y Crece    \n",
       "1     Bolsas hoy | Invierte y Crece    \n",
       "2     Bolsas hoy | Invierte y Crece    \n",
       "3     Bolsas hoy | Invierte y Crece    \n",
       "4     Bolsas hoy | Invierte y Crece    \n",
       "...                              ...   \n",
       "2220      Bolsas hoy | Esteban Pérez   \n",
       "2221      Bolsas hoy | Esteban Pérez   \n",
       "2222      Bolsas hoy | Esteban Pérez   \n",
       "2223      Bolsas hoy | Esteban Pérez   \n",
       "2224      Bolsas hoy | Esteban Pérez   \n",
       "\n",
       "                                              key_terms  \n",
       "0     [S&P 500,  Nasdaq,  DAX,  Eurostoxx,  Oro,  Cr...  \n",
       "1     [S&P 500 (SPX),  ETF SPY,  Nasdaq,  ETF Triple...  \n",
       "2     [S&P 500,  Nasdaq,  Bitcoin,  Oro,  Acciones t...  \n",
       "3     [Inditex, Alphabet (Google), Walt Disney, Acci...  \n",
       "4     [IBEX, DAX, Eurostoxx, S&P 500, Nasdaq, Bitcoi...  \n",
       "...                                                 ...  \n",
       "2220  [Inditex, AXA, Mapfre, Bering, Sirius, Pfizer ...  \n",
       "2221  [Charter Communications (CHTR),  Lemonade (LMN...  \n",
       "2222                    [Charter Communications (CHTR)]  \n",
       "2223                             [S&P 500, Nasdaq, Oro]  \n",
       "2224  [Oro, Bonos a 2 y 10 años, Acciones (en genera...  \n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_summaries_df[[\"channel_name\",\"key_terms\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "login(token=os.environ.get('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2004, 14), Test shape: (221, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/3s22b27525jc3bm0m923h36h3wg489/T/ipykernel_8883/2328981104.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_df = all_summaries_df.groupby(\"channel_name\", group_keys=False).apply(lambda x: x.sample(frac=0.1, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Tomar el 10% de cada canal para test y el 90% para train\n",
    "test_df = all_summaries_df.groupby(\"channel_name\", group_keys=False).apply(lambda x: x.sample(frac=0.1, random_state=42))\n",
    "train_df = all_summaries_df.drop(test_df.index)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 11.42ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:43<00:00, 43.13s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 29.20ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:05<00:00,  5.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/AndresR2909/youtube_transcriptions_summaries_2025_gpt4o/commit/07ff353bf201ee1a8169f1484a49038740876b8a', commit_message='Upload dataset', commit_description='', oid='07ff353bf201ee1a8169f1484a49038740876b8a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/AndresR2909/youtube_transcriptions_summaries_2025_gpt4o', endpoint='https://huggingface.co', repo_type='dataset', repo_id='AndresR2909/youtube_transcriptions_summaries_2025_gpt4o'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_train = Dataset.from_pandas(train_df)\n",
    "hf_test = Dataset.from_pandas(test_df)\n",
    "\n",
    "hf_dataset = DatasetDict({\n",
    "    \"train\": hf_train,\n",
    "    \"test\": hf_test\n",
    "})\n",
    "\n",
    "hf_dataset.push_to_hub(\"AndresR2909/youtube_transcriptions_summaries_2025_gpt4o\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
